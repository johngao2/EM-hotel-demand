{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "from ast import literal_eval\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load transaction data\n",
    "trans_df = pd.read_csv('../../../data/cabot_data/sprint_3/trans_s3_raw.csv',\n",
    "                       parse_dates=['LOOK_DATE'])\n",
    "\n",
    "# load predicted lambdas\n",
    "results_df = pd.read_csv('sprint4_results.csv')\n",
    "\n",
    "# load compatible types\n",
    "compat_df = pd.read_csv('mu_matrix_indep.csv')\n",
    "\n",
    "n_intraday = 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get binary value from purchases\n",
    "trans_df['PURCHASE_COUNT'] = trans_df['PRODUCT'].astype(str) != 'nan'\n",
    "trans_df['PURCHASE_COUNT'] = trans_df.apply(lambda row: 1 if row['PURCHASE_COUNT'] == True else 0, axis=1)\n",
    "\n",
    "# get look weeks and look_dow\n",
    "trans_df['LOOK_WEEK'] = trans_df.apply(lambda row: row['LOOK_DATE'].week, axis=1)\n",
    "trans_df['LOOK_DOW'] = trans_df.apply(lambda row: row['LOOK_DATE'].dayofweek, axis=1)\n",
    "\n",
    "# transform look day into numbers\n",
    "trans_df['LOOK_DOY'] = trans_df.apply(lambda row: row['LOOK_DATE'].dayofyear - 1, axis=1)\n",
    "\n",
    "# process predicted lambdas\n",
    "num_days = 299\n",
    "lamb_df = results_df.iloc[results_df.index > len(results_df) - (num_days + 1),:]\n",
    "lamb_df = lamb_df.reset_index().drop(['index','var'], axis=1)\n",
    "lamb_df['LOOK_DOY'] = lamb_df.index + 1\n",
    "lamb_df = lamb_df.rename(index=str, columns={\" value\": \"pred_lambda\"})\n",
    "lamb_df = lamb_df.set_index('LOOK_DOY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## old code for getting lambda * xi as a residual\n",
    "\n",
    "# # multiply xi by compatible types\n",
    "\n",
    "# # create index for each day\n",
    "# days_rep = np.arange(1, num_days + 1)\n",
    "# days_rep = np.repeat(days_rep, num_intraday)\n",
    "# compat_df['day'] = days_rep\n",
    "# compat_df = compat_df.drop(['idx'], axis=1).set_index('day')\n",
    "\n",
    "# # get type probs\n",
    "# probs_df = results_df.iloc[results_df.index < compat_df.shape[1],:]\n",
    "# probs_df.index = probs_df.index + 1\n",
    "# probs_df = probs_df.drop(['var'], axis=1)\n",
    "# probs_df = probs_df.rename(index=str, columns={\" value\": \"value\"})\n",
    "\n",
    "# # multiply type probs by compatible types\n",
    "# compat_df = compat_df.mul(probs_df['value'])\n",
    "\n",
    "\n",
    "# # sum in each time period\n",
    "# compat_df['sum_xi'] = compat_df.sum(axis=1)\n",
    "# compat_df = compat_df[['sum_xi']]\n",
    "\n",
    "# # multiply each x_i aggregate by lambda\n",
    "# sum_lamb_xi_vec = []\n",
    "# for index, row in compat_df.iterrows():\n",
    "#     pred_lambda = lamb_df.loc[index, 'pred_lambda']\n",
    "#     sum_lambda_xi = row['sum_xi'] * pred_lambda\n",
    "#     sum_lamb_xi_vec.append(sum_lambda_xi)\n",
    "    \n",
    "# compat_df['sum_lamb_xi'] = sum_lamb_xi_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predicted lambdas into main df\n",
    "trans_df = trans_df.merge(lamb_df, on='LOOK_DOY')\n",
    "\n",
    "# get daily counts and diff\n",
    "daily_count = trans_df.groupby('LOOK_DOY').sum()\n",
    "daily_count['diff'] = daily_count['PURCHASE_COUNT'] - daily_count['pred_lambda']\n",
    "\n",
    "# get weekly counts and diff\n",
    "weekly_count = trans_df.groupby('LOOK_WEEK').sum()\n",
    "weekly_count['diff'] = weekly_count['PURCHASE_COUNT'] - weekly_count['pred_lambda']\n",
    "\n",
    "# get dow counts and diff\n",
    "dow_count = trans_df.groupby('LOOK_DOW').sum()\n",
    "dow_count['diff'] = dow_count['PURCHASE_COUNT'] - dow_count['pred_lambda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.2192"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.1632*81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure for daily differences\n",
    "plt.figure(figsize=(20,60))\n",
    "plt.barh(daily_count.index, daily_count['diff'], align='center', alpha=0.5)\n",
    "plt.yticks(daily_count.index)\n",
    "plt.ylabel('Look_Day')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_day vs predicted count difference')\n",
    "plt.savefig('daily_count_diff.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure for weekly differences\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(weekly_count.index, weekly_count['diff'], align='center', alpha=0.5, color='g')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('Look_week')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_week vs predicted count difference')\n",
    "plt.savefig('weekly_count_diff.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure for weekly differences\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.barh(dow_count.index, dow_count['diff'], align='center', alpha=0.5, color='r')\n",
    "plt.yticks(dow_count.index)\n",
    "plt.ylabel('Look_dow')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_dow vs predicted count difference')\n",
    "plt.savefig('dow_count_diff.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save figure for weekly counts\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(weekly_count.index, weekly_count['PURCHASE_COUNT'], align='center', alpha=0.5, color='g')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('Look_week')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Weekly Counts')\n",
    "plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
