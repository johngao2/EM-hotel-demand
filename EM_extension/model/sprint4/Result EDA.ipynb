{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta, date\n",
    "from ast import literal_eval\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# load transaction data\n",
    "trans_df = pd.read_csv('../../../data/cabot_data/sprint_3/trans_s3_raw.csv',\n",
    "                       parse_dates=['LOOK_DATE'])\n",
    "\n",
    "# load predicted lambdas\n",
    "results_df = pd.read_csv('sprint4_results.csv')\n",
    "\n",
    "n_intraday = 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_diffs = pd.read_csv('../../../data/cabot_data/sprint_4/ba_diffs.csv', index_col='Unnamed: 0')\n",
    "\n",
    "# process ba_diffs\n",
    "ba_diffs['LOOK_WEEK'] = daily_count['LOOK_WEEK']/n_intraday\n",
    "ba_diffs_weekly = ba_diffs.groupby(by='LOOK_WEEK').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get binary value from purchases\n",
    "trans_df['PURCHASE_COUNT'] = trans_df['PRODUCT'].astype(str) != 'nan'\n",
    "trans_df['PURCHASE_COUNT'] = trans_df.apply(lambda row: 1 if row['PURCHASE_COUNT'] == True else 0, axis=1)\n",
    "\n",
    "# get look weeks and look_dow\n",
    "trans_df['LOOK_WEEK'] = trans_df.apply(lambda row: row['LOOK_DATE'].week, axis=1)\n",
    "trans_df['LOOK_DOW'] = trans_df.apply(lambda row: row['LOOK_DATE'].dayofweek, axis=1)\n",
    "\n",
    "# transform look day into numbers\n",
    "trans_df['LOOK_DOY'] = trans_df.apply(lambda row: row['LOOK_DATE'].dayofyear - 1, axis=1)\n",
    "\n",
    "# process predicted lambdas\n",
    "num_days = 299\n",
    "lamb_df = results_df.iloc[results_df.index > len(results_df) - (num_days + 1),:]\n",
    "lamb_df = lamb_df.reset_index().drop(['index','var'], axis=1)\n",
    "lamb_df['LOOK_DOY'] = lamb_df.index + 1\n",
    "lamb_df = lamb_df.rename(index=str, columns={\" value\": \"pred_lambda\"})\n",
    "lamb_df = lamb_df.set_index('LOOK_DOY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge predicted lambdas into main df\n",
    "trans_df = trans_df.merge(lamb_df, on='LOOK_DOY')\n",
    "\n",
    "# get daily counts and diff\n",
    "daily_count = trans_df.groupby('LOOK_DOY').sum()\n",
    "daily_count['diff'] = daily_count['PURCHASE_COUNT'] - daily_count['pred_lambda']\n",
    "\n",
    "# get weekly counts and diff\n",
    "weekly_count = trans_df.groupby('LOOK_WEEK').sum()\n",
    "weekly_count['diff'] = weekly_count['PURCHASE_COUNT'] - weekly_count['pred_lambda']\n",
    "\n",
    "# get dow counts and diff\n",
    "dow_count = trans_df.groupby('LOOK_DOW').sum()\n",
    "dow_count['diff'] = dow_count['PURCHASE_COUNT'] - dow_count['pred_lambda']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find types that are rarely compatible\n",
    "\n",
    "# load compatible types\n",
    "compat_df = pd.read_csv('mu_matrix_indep.csv')\n",
    "compat_df = compat_df.set_index('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum each col\n",
    "compat_sums = pd.DataFrame(compat_df.sum(axis=0), columns=['sum'])\n",
    "compat_sums = compat_sums.sort_values(by='sum')#sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compat_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot compatible type sums\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(range(1,4901), compat_sums['sum'], alpha=0.5)\n",
    "# plt.yticks(daily_count.index)\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Type (sorted by freq)')\n",
    "plt.title('Compatible type frequencies, sorted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figures for differences b/w lambda and actual counts\n",
    "\n",
    "# save figure for daily differences\n",
    "plt.figure(figsize=(20,60))\n",
    "plt.barh(daily_count.index, daily_count['diff'], align='center', alpha=0.5)\n",
    "plt.yticks(daily_count.index)\n",
    "plt.ylabel('Look_Day')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_day vs predicted count difference')\n",
    "plt.savefig('daily_count_diff.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# save figure for weekly differences\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(weekly_count.index, weekly_count['diff'], align='center', alpha=0.5, color='g')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('Look_week')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_week vs predicted count difference')\n",
    "plt.savefig('weekly_count_diff.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# save figure for dow differences\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.barh(dow_count.index, dow_count['diff'], align='center', alpha=0.5, color='r')\n",
    "plt.yticks(dow_count.index)\n",
    "plt.ylabel('Look_dow')\n",
    "plt.xlabel('Count vs Predicted count difference')\n",
    "plt.title('Look_dow vs predicted count difference')\n",
    "plt.savefig('dow_count_diff.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts and lambdas\n",
    "\n",
    "# daily counts\n",
    "plt.figure(figsize=(20,60))\n",
    "plt.barh(daily_count.index, daily_count['PURCHASE_COUNT'], align='center', alpha=0.5, color='b')\n",
    "plt.yticks(daily_count.index)\n",
    "plt.ylabel('Look_day')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Daily Counts')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# daily lambdas\n",
    "plt.figure(figsize=(20,60))\n",
    "plt.barh(daily_count.index, daily_count['pred_lambda'], align='center', alpha=0.5, color='y')\n",
    "plt.yticks(daily_count.index)\n",
    "plt.ylabel('Lambda')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Daily Lambdas')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# save figure for weekly counts\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(weekly_count.index, weekly_count['PURCHASE_COUNT'], align='center', alpha=0.5, color='g')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('Look_week')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Weekly Counts')\n",
    "plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# weekly lambdas\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(weekly_count.index, weekly_count['pred_lambda'], align='center', alpha=0.5, color='b')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('Lambda')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Weekly Lambdas')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# daily ba_diffs\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(ba_diffs.index, ba_diffs['BA_DIFF'], align='center', alpha=0.5, color='b')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('BA_DIFF')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Daily ba_diff')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "# weekly ba_diffs\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.barh(ba_diffs_weekly.index, ba_diffs_weekly['BA_DIFF'], align='center', alpha=0.5, color='g')\n",
    "plt.yticks(weekly_count.index)\n",
    "plt.ylabel('BA_DIFF')\n",
    "plt.xlabel('Count')\n",
    "plt.title('Weekly ba_diff')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LL convergence graph\n",
    "lls = pd.read_csv('lls_indep.csv')\n",
    "lls = lls.iloc[1:,:]\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(lls.index, lls['LL'], alpha=0.5, color='g')\n",
    "# plt.xticks(weekly_count.index)\n",
    "plt.ylabel('LL')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('LL over iterations')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "#LL diffs graph\n",
    "ll_diffs = lls['LL'] - lls['LL'].shift(+1)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(lls.index, ll_diffs, alpha=0.5, color='b')\n",
    "# plt.xticks(weekly_count.index)\n",
    "plt.ylabel('LL_diff')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('LL_diff over iterations')\n",
    "# plt.savefig('weekly_counts.png', format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## old code for getting lambda * xi as a residual\n",
    "\n",
    "# # multiply xi by compatible types\n",
    "\n",
    "# # create index for each day\n",
    "# days_rep = np.arange(1, num_days + 1)\n",
    "# days_rep = np.repeat(days_rep, num_intraday)\n",
    "# compat_df['day'] = days_rep\n",
    "# compat_df = compat_df.drop(['idx'], axis=1).set_index('day')\n",
    "\n",
    "# # get type probs\n",
    "# probs_df = results_df.iloc[results_df.index < compat_df.shape[1],:]\n",
    "# probs_df.index = probs_df.index + 1\n",
    "# probs_df = probs_df.drop(['var'], axis=1)\n",
    "# probs_df = probs_df.rename(index=str, columns={\" value\": \"value\"})\n",
    "\n",
    "# # multiply type probs by compatible types\n",
    "# compat_df = compat_df.mul(probs_df['value'])\n",
    "\n",
    "\n",
    "# # sum in each time period\n",
    "# compat_df['sum_xi'] = compat_df.sum(axis=1)\n",
    "# compat_df = compat_df[['sum_xi']]\n",
    "\n",
    "# # multiply each x_i aggregate by lambda\n",
    "# sum_lamb_xi_vec = []\n",
    "# for index, row in compat_df.iterrows():\n",
    "#     pred_lambda = lamb_df.loc[index, 'pred_lambda']\n",
    "#     sum_lambda_xi = row['sum_xi'] * pred_lambda\n",
    "#     sum_lamb_xi_vec.append(sum_lambda_xi)\n",
    "    \n",
    "# compat_df['sum_lamb_xi'] = sum_lamb_xi_vec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
